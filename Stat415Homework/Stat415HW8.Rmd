---
title: "Stat/Math 415 Homework 8"
subtitle: "Due Friday Nov 22; Joseph Sepich (jps6444)"
output:
  pdf_document:
    toc: false
    toc_depth: 2
    number_sections: true
    keep_tex: false
---

# Problem 9.3-1

Problem Constraints:

* $H_0$: $\mu_1 = \mu_2 = \mu_3$
* $H_1$: not all equal
* $\alpha = 0.05$

This problem relates to the analysis of variacne (ANOVA). We need to use various error sources to determine if we should reject the null hypothesis. First of all let's define three error sources (where n and m are the sample size and number of groups respectively):

\[SS_E = SS_{TO}-SS_T = \Sigma_{i=1}^m\Sigma_{j=1}^n(x_{ij}-\overline{x_{i.}})^2; MS_E = \frac{SS_E}{n - m}\]
\[SS_T = \Sigma_{i=1}^m(\overline{x_{i.}}-\overline{x_{..}})^2n_i; MS_{TE} = \frac{SS_T}{m-1}\]
\[SS_{TO} = \Sigma_{i=1}^m\Sigma_{j=1}^n(x_{ij}-\overline{x_{..}})^2\]

We can then use these error sources to define the F Distribution:

\[F = \frac{MS_T}{MS_E}\]

And we reject the null hypothesis if $F \geq F_{\alpha}(m-1, n-m)$. Let's now calculate the required values:


```{r}
x_1 <- c(5, 9, 6, 8)
x_2 <- c(11, 13, 10, 12)
x_3 <- c(10, 6, 9, 9)

x_matrix <- data.frame(x_1 = x_1, x_2 = x_2, x_3 = x_3)

n <- 4
m <- 3

mean_1 <- sum(x_1) / n
mean_2 <- sum(x_2) / n
mean_3 <- sum(x_3) / n

means <- c(mean_1, mean_2, mean_3)
total_mean <- sum(means) / m

SS_T <- 0
SS_E <- 0
SS_TO <- 0

for (i in 1:m) {
  SS_T <- SS_T + n * (means[i] - total_mean)^2
}

for (i in 1:m) {
  for (j in 1:n) {
    SS_E <- SS_E + (x_matrix[j, i] - means[i])^2
  }
}

for (i in 1:m) {
  for (j in 1:n) {
    SS_TO <- SS_TO + (x_matrix[j, i] - total_mean)^2
  }
}

MS_T <- SS_T / (m-1)
MS_E <- SS_E / (n * m - m)

F_var <- MS_T / MS_E

print(paste0('SS(TO) is ', SS_TO))
print(paste0('SS(T) is ', SS_T))
print(paste0('SS(E) is ', SS_E))
print(paste0('MS(T) is ', MS_T))
print(paste0('MS(E) is ', MS_E))
print(paste0('F test statistic is ', F_var))
```

Using a significance level of $\alpha = 0.05$ we can reference the value of $F_{\alpha}(m-1, n-m) = F_{0.05}(2, 9) = 4.2565$ in the F distribution table reference. Since our F test statistic is $7.875 > 4.2565$, we can **reject** our null hypothesis ($H_0$) of $\mu_1 = \mu_2 = \mu_3$.


# Problem 9.3-15

Problem Constraints:

* $H_0$: $\mu_1 = \mu_2 = \mu_3$
* $H_1$: not all equal
* $\alpha = 0.05$

This problem relates to the analysis of variacne (ANOVA). We need to use various error sources to determine if we should reject the null hypothesis. First of all let's define three error sources (where n and m are the sample size and number of groups respectively):

\[SS_E = SS_{TO}-SS_T = \Sigma_{i=1}^m\Sigma_{j=1}^n(x_{ij}-\overline{x_{i.}})^2; MS_E = \frac{SS_E}{n - m}\]
\[SS_T = \Sigma_{i=1}^m(\overline{x_{i.}}-\overline{x_{..}})^2n_i; MS_{TE} = \frac{SS_T}{m-1}\]
\[SS_{TO} = \Sigma_{i=1}^m\Sigma_{j=1}^n(x_{ij}-\overline{x_{..}})^2\]

We can then use these error sources to define the F Distribution:

\[F = \frac{MS_T}{MS_E}\]

And we reject the null hypothesis if $F \geq F_{\alpha}(m-1, n-m)$. Let's now calculate the required values:


```{r}
x_1 <- c(500, 650, 530, 680, NA)
x_2 <- c(700, 620, 780, 830, 860)
x_3 <- c(500, 520, 400, 580, 410)

x_matrix <- data.frame(x_1 = x_1, x_2 = x_2, x_3 = x_3)

n <- c(length(x_1) - 1, length(x_2), length(x_3))
m <- 3

mean_1 <- sum(x_1, na.rm = TRUE) / n[1]
mean_2 <- sum(x_2, na.rm = TRUE) / n[2]
mean_3 <- sum(x_3, na.rm = TRUE) / n[3]

means <- c(mean_1, mean_2, mean_3)

total_mean <- 0
for (i in 1:m) {
  total_mean <- total_mean + sum(x_matrix[,i], na.rm = TRUE)
}
total_mean <- total_mean / sum(n)

SS_T <- 0
SS_E <- 0
SS_TO <- 0

for (i in 1:m) {
  SS_T <- SS_T + n[i] * (means[i] - total_mean)^2
}

for (i in 1:m) {
  for (j in 1:n[i]) {
    if (is.na(x_matrix[j, i])) {
      break
    }
    SS_E <- SS_E + (x_matrix[j, i] - means[i])^2
  }
}

for (i in 1:m) {
  for (j in 1:n[i]) {
    if (is.na(x_matrix[j, i])) {
      break
    }
    SS_TO <- SS_TO + (x_matrix[j, i] - total_mean)^2
  }
}

MS_T <- SS_T / (m-1)
MS_E <- SS_E / (sum(n) - m)

F_var <- MS_T / MS_E

print(paste0('SS(TO) is ', SS_TO))
print(paste0('SS(T) is ', SS_T))
print(paste0('SS(E) is ', SS_E))
print(paste0('MS(T) is ', MS_T))
print(paste0('MS(E) is ', MS_E))
print(paste0('F test statistic is ', F_var))
```

Using a significance level of $\alpha = 0.05$ we can reference the value of $F_{\alpha}(m-1, n-m) = F_{0.05}(2, 11) = 3.9823$ in the F distribution table reference. Since our F test statistic is $12.47 > 3.9823$, we can **reject** our null hypothesis ($H_0$) of $\mu_1 = \mu_2 = \mu_3$. This implies that different feed supplements do **not** have the same affect on cow weight.


# Problem 8.4-3

Problem Constraints

* $H_0$: $m = 5.900$
* $H_1$: $m > 5.900$
* $n = 25$
* $\alpha = 0.05$

```{r}
weight <- c(5.625, 5.665, 5.697, 5.837, 5.863, 5.870, 5.878, 5.884, 5.908, 5.967,
            6.019, 6.020, 6.029, 6.032, 6.037, 6.045, 6.049, 6.050, 6.079, 6.116,
            6.159, 6.186, 6.199, 6.307, 6.387)
n <- 25
```

## Part a

We are going to use the sign test to test our hypothesis. The sign test inspects the sign value of $x_i - m_0$. After we create this, we simply have a binomial variable Y, an indicator of whether the data point is above or below our $m_0$. Y has the parameters $n=25$ and $p=0.5$, since our null hypothesis is about the median, Y would have half the values negative and half positive if it is the true median. Let's calculate our values:

```{r include = FALSE}
library(tidyverse)
```

```{r}
calculations <- data.frame(weight = weight)

calculations$med <- 5.9
calculations$Difference <- calculations$weight - calculations$med
calculations$Sign <- if_else(calculations$Difference > 0, TRUE, FALSE)

calculations %>%
  head()
```

Since the weight vector is ordered, and 8 values are negative sign in a 25 row table, we know the value of Y = 17 in this case (the binomial distribution). Let's calculate our test statistic:

\[Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} = \frac{\frac{17}{25} - 0.5}{\sqrt{\frac{0.25}{25}}}\]

```{r}
Z <- (17 / 25 - 0.5) / (sqrt((0.5 * 0.5)/n))
paste0('The value of Z is ', Z)
```

Using the critical region approach we have $Z > Z_{\alpha} = Z_{0.05} = 1.645$. Since our test statistic $1.8 > 1.645$ we **can** reject the null hypothesis that the median is 5.900 meaning we conclude the median weight of a Grape Jolly Rancher is not 5.900 grams.

## Part b

The Wilcoxon Test uses the same methodology, but also looks at the magnitude of our data. We are under the assumption that our data is somewhat symmetrically distributed. We already know the sign, but we also want to know rank: the magnitude of the difference from the null hypothesis. Let's calculate this:

```{r}
calculations$AbsDiff <- abs(calculations$Difference)
calculations$Rank <- rank(calculations$AbsDiff)

calculations %>%
  select(weight, med, AbsDiff, Rank, Sign) %>%
  arrange(Rank)
```

We can now use the rank to calculate the random variable W. This random variable will enable use to get our test statistic. W is defined:

\[W = \Sigma_{i=1}^nrank_i*sign_i\]

Since our variance for W is $n(n+1)(2n+2)/6$, we can use this to create our test statistic:

\[Z = \frac{W - 0}{\sqrt{\frac{n(n+1)(2n+1)}{6}}}\]

Let's calculate these values:

```{r}
W <- sum(calculations$Rank * if_else(calculations$Sign == TRUE, 1, -1))
Z <- W / (sqrt((n * (n + 1) * ( 2 * n + 1)) / 6))

paste0('The value of W is ', W)
paste0('The value of Z is ', Z)
```

Using the critical region approach at $\alpha = 0.05$ significance level, we reject if $Z > Z_{\alpha} = Z_{0.05} = 1.645$. Given our test statistic of $2.301 > 1.645$ we **can** reject the null hypothesis $H_0$ that $m = 5.900$ meaning we conclude the median weight of a Grape Jolly Rancher is not 5.900 grams.

## Part c

Since we are using the t test to conduct a hypothesis test, we are assuming a normal distribution of the data. Recall the difference values for each pair we found before:

```{r}
calculations %>%
  select(weight, med, Difference)
```

Using this data we must obtain the sample mean $\overline{D}$, which is the mean of the Difference values. This is then used in our test statistic:

\[t = \frac{\overline{D} - (5.900 - 5.900)}{\sqrt{S_D/n}}\]
\[S_D^2 = \Sigma_{i=1}^n(D_i - \overline{D})^2 / (n-1)\]

```{r}
meanD <- sum(calculations$Difference) / n
sd <- sum((calculations$Difference - meanD)^2) / (n-1)

t <- meanD/sqrt(sd/n)

paste0('Difference sample variance SD^2 is ', sd)
paste0('Test statistic t is ', t)
```

Given a significance level of $\alpha = 0.05$, using the t table we have the critical region $t(n-1) > t_{\alpha}(n-1) = t_{0.05}(24) = 1.711$. Since our test statistic $2.608 > 1.711$ we **can** reject the null hypothesis that $m = 5.900$ meaning we conclude the median weight of a Grape Jolly Rancher is not 5.900 grams.

## Part d

The sign test is the easiest test to do, because it requires no assumptions about the data, but the sign test is clearly also least likely to reject the null hypothesis, since we are less confident about the distribution of the data. The Wilcoxon test is reasonably powerful when assuming a distribution is symmetric, but the t test clearly works better if you know the data is normally distributed.

# Problem 8.4-7

Problem Constraints

* m is median
* $H_0$: $m = 1.14$
* $H_1$: $m > 1.14$
* $n = 14$
* $\alpha \approx 0.10$

## Part a

In a Wilcoxon test, we use a test statistic in the normal standard distribution table. This would make our critical region:

\[Z > Z_{\alpha} = Z_{0.10} = 1.28\]

## Part b

The Wilcoxon Test looks at the magnitude of our data. We are under the assumption that our data is somewhat symmetrically distributed. We need to calculate the sign, but we also want to know rank: the magnitude of the difference from the null hypothesis. Let's calculate this:

```{r}
weight <- c(1.12, 1.13, 1.19, 1.25, 1.06, 1.31, 1.12, 1.23, 1.29, 1.17, 1.20,
            1.11, 1.18, 1.23)
n <- 14

calculations <- data.frame(weight = weight)

calculations$med <- 1.14
calculations$Difference <- calculations$weight - calculations$med
calculations$Sign <- if_else(calculations$Difference > 0, TRUE, FALSE)
calculations$AbsDiff <- abs(calculations$Difference)

calculations <- calculations %>%
  select(weight, med, AbsDiff, Sign) %>%
  arrange(AbsDiff)

calculations
```

Note that some of our values have the same magnitude. In ties we take the average range of ranks and insert that as each variables rank value:

```{r}
calculations$Rank <- c(1, 2.5, 2.5, 4.5, 4.5, 6, 7, 8, 9, 10.5, 10.5, 12, 13, 14)

calculations %>%
  select(weight, Rank)
```

We can now use the rank to calculate the random variable W. This random variable will enable use to get our test statistic. W is defined:

\[W = \Sigma_{i=1}^nrank_i*sign_i\]

Since our variance for W is $n(n+1)(2n+2)/6$, we can use this to create our test statistic:

\[Z = \frac{W - 0}{\sqrt{\frac{n(n+1)(2n+1)}{6}}}\]

Let's calculate these values:

```{r}
W <- sum(calculations$Rank * if_else(calculations$Sign == TRUE, 1, -1))
Z <- W / (sqrt(n * (n + 1) * ( 2 * n + 1) / 6))

paste0('The value of W is ', W)
paste0('The value of Z is ', Z)
```

Since our test statistice $2.071 > 1.28$ we would therefore **reject** the null hypothesis that $m = 1.14$ meaning we conclude that the median weight of the one pound carrot bags is not 1.14 pounds.

## Part c

The P-value of this test is the probability that the test statistic is more extreme than our observed test statistic: 

\[P(Z > 2.07) = 1 - P(Z \leq 2.07) = 1 - 0.9808 = 0.0192\]

This makes our p-value **0.0192**. 

# Problem 8.4-15

Problem Constraints

* $\alpha = 0.05$
* $H_0$: $m_x = m_y$
* $H_1$: $m_x \neq m_y$


```{r}
x <- c(-2.3864, -2.2171, -1.9148, -1.9097, -1.4883, -1.2007, -1.1077, -0.3601,
       0.4325, 1.0598, 1.3035, 1.5241, 1.7133, 1.7656, 2.4912)
y <- c(-1.7613, -0.9391, -0.7437, -0.5530, -0.2469, 0.0647, 0.2031, 0.3219, 0.3579,
       0.6431, 0.6557, 0.6724, 0.6762, 0.9041, 1.3571)
n <- 15
```

For our Wilcoxon test we must first assign ranks to every value in the dataset. Any ties will be settled by giving each tied value the average of their ranks.

```{r}
wilcoxon <- data.frame(x = x, y = y)

wilcoxon
```

```{r}
wilcoxon$xRank <- 0
wilcoxon$yRank <- 0
wilcoxon$xRank <- c(1, 2, 3, 4, 6, 7, 8, 12, 18, 24, 25, 27, 28, 29, 30)
wilcoxon$yRank <- c(5, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26)
```

Just like with the one-sided hypotheses we have a random variable W. We can use the wilcoxon statistic to find our test statistic. W is defined:

\[W = \Sigma_{i=1}^nrank(y_i); W - N(n_2(n_1 + n_2 + 1)/2, n_1n_2(n_1+n_2+1)/12)\]
\[Z = \frac{W - n_2(n_1 + n_2 + 1)/2}{\sqrt{n_1n_2(n_1+n_2+1)/12}}\]

```{r}
W <- sum(wilcoxon$yRank)
Z <- (W - n * (n + n + 1) / 2) / sqrt((n * n * (n + n + 1))/12)

paste0('The value of W is ', W)
paste0('The value of Z is ', Z)
```

Using the critical region approach we can test that with $\alpha = 0.05$ the critical region would be $|Z| > Z_{\alpha} = Z_{0.05} = 1.96$. Since our test statistic $0.35 < 1.96$ we **cannot** reject the null hypothesis that the medians are equal. That means that we cannot say with 95% confidence that the two medians are not equal.











